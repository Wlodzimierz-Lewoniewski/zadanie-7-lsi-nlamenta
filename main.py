import re
import numpy as np

# zmiana na maÅ‚e litery
def tokenizacja(text):
    return re.findall(r'\b\w+\b', text.lower())

# input
n = int(input().strip())
dokumenty = [input().strip() for i in range(n)]
zapytanie = input().strip()
k = int(input().strip())

# Przygotuj macierz term-dokument ğ¶
termy = sorted(set(word for doc in dokumenty for word in tokenizacja(doc)))
term_document = np.array([[1 if term in tokenizacja(doc) else 0 for doc in dokumenty] for term in termy])

# PrzeprowadÅº dekompozycjÄ™ macierzy ğ¶wg SVD,
U, S, Vt = np.linalg.svd(term_document, full_matrices=False)

# PrzeprowadÅº aproksymacjÄ™ rzÄ™du ğ‘˜, otrzymujÄ…c ğ¶ğ‘˜
Uk = U[:, :k]
Sk = np.diag(S[:k])
Vk = Vt[:k, :]

# Oblicz macierz ğ›´ğ‘˜ğ‘‰ğ‘˜ğ‘‡, ktÃ³rej kolumny sÄ… wektorami dokumentÃ³w w zredukowanej przestrzeni
Ck = Uk @ Sk @ Vk

# Oblicz wektor zapytania w zredukowanej przestrzeni ğ‘ğ‘˜
zapytanie_wektor = np.array([1 if term in tokenizacja(zapytanie) else 0 for term in termy])
zapytanie_zredukowane = np.linalg.inv(Sk) @ Uk.T @ zapytanie_wektor

# Oblicz podobieÅ„stwo zapytania do kaÅ¼dego z dokumentÃ³w wg miary cosinusa
miara_cosinus = []
for dok_wektor in (Sk @ Vk).T:
    numerator = np.dot(zapytanie_zredukowane, dok_wektor)
    denominator = np.linalg.norm(zapytanie_zredukowane) * np.linalg.norm(dok_wektor)
    similarity = numerator / denominator if denominator != 0 else 0
    miara_cosinus.append(round(float(similarity), 2))

# output
print(miara_cosinus)
